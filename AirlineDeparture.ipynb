{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "#%%capture\n",
                "#!sudo apt update\n",
                "#!apt-get install openjdk-8-jdk-headless - qq > /dev/null\n",
                "#!wget - q https: // dlcdn.apache.org/spark/spark-3.3.0/spark-3.3.0-bin-hadoop2.tgz\n",
                "#!tar xf spark-3.3.0-bin-hadoop2.tgz\n",
                "#!pip install - r requirements.txt\n",
                "\n",
                "import os\n",
                "from kaggle.api.kaggle_api_extended import KaggleApi\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "from pyspark.sql.types import StructType, StructField, StringType, DoubleType, FloatType\n",
                "from pyspark.sql import SparkSession\n",
                "from pyspark.sql.functions import monotonically_increasing_id, col, udf, rand\n",
                "import matplotlib.pyplot as plt\n",
                "import math\n",
                "import pyspark.sql as ps\n",
                "from zlib import crc32\n",
                "import time as tm\n",
                "from datetime import datetime as dt\n",
                "from dateutil import parser\n",
                "import itertools\n",
                "from collections import defaultdict\n",
                "from dataclasses import dataclass\n",
                "from pyspark.sql import functions as F\n",
                "from pyspark.rdd import RDD\n",
                "from pyspark.broadcast import Broadcast\n",
                "import findspark\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "path = './data'\n",
                "worker_nodes = \"*\"\n",
                "problem_to_solve = 'CANCELLED'\n",
                "\n",
                "dataset_limit = 100000\n",
                "use_all_dataset_frames = True\n",
                "fold_number = 10\n",
                "load_cached = True\n",
                "\n",
                "def print_and_save_time(s: str):\n",
                "  print(s)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# DA SCRIVERE\n",
                "- perche' usiamo i dataframe invece degli rdd nella prima parte\n",
                "- aggiungere k fold cross validation\n",
                "- aggiungere griglia parametri\n",
                "- aggiungere label stratification -> OK\n",
                "- aggiungere performance modello pyspark\n",
                "- aggiungere check e info extra su dataset di base (es sbilanciamento)\n",
                "- auroc, auprc, f1, \n",
                "- confronto con tree classifier\n",
                "- confrontare ogni pezzo con MLLib\n",
                "- perche' sgd invece di no?"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Data Download"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "os.environ['KAGGLE_USERNAME'] = \"davidetricella\"\n",
                "os.environ['KAGGLE_KEY'] = \"e1ab3aae4a07f36b37a3a8bace74d9df\"\n",
                "\n",
                "\n",
                "dataset = 'yuanyuwendymu/airline-delay-and-cancellation-data-2009-2018'\n",
                "path = './data'"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def download_dataset():\n",
                "    if not os.path.isdir(path):\n",
                "        os.mkdir(path)\n",
                "    if not os.listdir(path):\n",
                "        try:\n",
                "            api = KaggleApi()\n",
                "            api.authenticate()\n",
                "            api.dataset_download_files(dataset, path, unzip=True, quiet=False)\n",
                "        except:\n",
                "            print(\"Error downloading the dataset\")\n",
                "\n",
                "download_dataset()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Data Loading"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "dataframe_schema = StructType([\n",
                "    StructField('FL_DATE', StringType(), True),\n",
                "    StructField('OP_CARRIER', StringType(), True),\n",
                "    StructField('ORIGIN', StringType(), True),\n",
                "    StructField('DEST', StringType(), True),\n",
                "    StructField('CRS_DEP_TIME', StringType(), True),\n",
                "    StructField('CRS_ARR_TIME', StringType(), True),\n",
                "    StructField('CANCELLED', StringType(), True),\n",
                "    StructField('DIVERTED', StringType(), True),\n",
                "    StructField('CRS_ELAPSED_TIME', StringType(), True),\n",
                "    StructField('DISTANCE', StringType(), True)\n",
                "])\n",
                "\n",
                "columns_to_get = [\n",
                "    'FL_DATE',\n",
                "    'OP_CARRIER',\n",
                "    'ORIGIN',\n",
                "    'DEST',\n",
                "    'CRS_DEP_TIME',\n",
                "    'CRS_ARR_TIME',\n",
                "    'CANCELLED',\n",
                "    'DIVERTED',\n",
                "    'CRS_ELAPSED_TIME',\n",
                "    'DISTANCE'\n",
                "]\n",
                "\n",
                "#Rounded max distance between airports found in the dataset\n",
                "max_distance = 4970\n",
                "\n",
                "findspark.init()\n",
                "findspark.find()\n",
                "\n",
                "spark = SparkSession.builder \\\n",
                ".appName(\"Airline Departure\") \\\n",
                ".master('local[' + worker_nodes + ']') \\\n",
                ".getOrCreate()\n",
                "\n",
                "context = spark.sparkContext\n",
                "\n",
                "#The rows are loaded fom all files or only the first one with a limit value\n",
                "def get_dataset(limit: float = -1, allFrames: bool = True):\n",
                "    files = os.listdir(path)\n",
                "    big_frame = spark.createDataFrame(\n",
                "        spark.sparkContext.emptyRDD(), schema=dataframe_schema)\n",
                "    if not allFrames:\n",
                "        files = [files[0]]\n",
                "\n",
                "    for f in files:\n",
                "        if f.endswith('.csv'):\n",
                "            frame = spark.read.option(\"header\", True).csv(path + '/' + f)\n",
                "            frame = frame.select(columns_to_get)\n",
                "            frame = frame.orderBy(rand())\n",
                "\n",
                "            if limit != -1:\n",
                "                frame = frame.limit(limit)\n",
                "\n",
                "            big_frame = frame.union(big_frame)\n",
                "\n",
                "    big_frame = big_frame.withColumn(\n",
                "        \"id\", monotonically_increasing_id()).orderBy(rand())\n",
                "    big_frame.count()\n",
                "\n",
                "    return big_frame"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Preprocessing"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### Chart Plotting Definitions"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "#These are the defintions of the charts plotted during data analysis, the main chart used is the bar charts, to have a grasp of the \n",
                "#various distributions of problematic flights regarding the most important columns chosen to train the model.\n",
                "#During charts plotting, the data has been collected, taking advantage of the really low numbers of problematic flights in the dataset.\n",
                "\n",
                "def plot_balancing_chart(data: ps.DataFrame, label: str):\n",
                "  total_positives = data.filter(col(label) == 1).count()\n",
                "  total_negatives = data.filter(col(label) == 0).count()\n",
                "  fig, ax = plt.subplots()\n",
                "\n",
                "  labels = ['REGULAR', label]\n",
                "  counts = [total_negatives, total_positives]\n",
                "  bar_colors = ['tab:blue', 'tab:red']\n",
                "\n",
                "  ax.bar(labels, counts, color=bar_colors)\n",
                "\n",
                "  ax.set_ylabel('Counts')\n",
                "  ax.set_title('Regular flights and problematic flights counts')\n",
                "\n",
                "  plt.show()\n",
                "\n",
                "\n",
                "def plot_problematic_flights_per_carrier_chart(data: ps.DataFrame, label: str):\n",
                "  problematic_flights = data.filter(col(label) == 1).collect()\n",
                "  fig, ax = plt.subplots()\n",
                "\n",
                "  flights_dict = defaultdict(int)\n",
                "  labels = []\n",
                "  counts = []\n",
                "\n",
                "  for row in problematic_flights:\n",
                "    flights_dict[row[\"OP_CARRIER\"]] += 1\n",
                "\n",
                "  for key in flights_dict:\n",
                "    single_carrier_total_flights = data.filter(col(\"OP_CARRIER\") == key).count()\n",
                "    flights_dict[key] = flights_dict[key] / single_carrier_total_flights * 100\n",
                "\n",
                "  mean = sum(flights_dict.values()) / len(flights_dict)\n",
                "\n",
                "  for key in flights_dict:\n",
                "    if flights_dict[key] > mean:\n",
                "      labels.append(key)\n",
                "      counts.append(flights_dict[key])\n",
                "  labels.append(\"Mean\")\n",
                "  counts.append(mean)\n",
                "\n",
                "  ax.bar(labels, counts)\n",
                "\n",
                "  ax.set_ylabel('Percentages')\n",
                "  ax.set_title('Problematic flights per carrier')\n",
                "\n",
                "  plt.show()\n",
                "\n",
                "def plot_problematic_flights_per_origin_chart(data: ps.DataFrame, label: str):\n",
                "  problematic_flights = data.filter(col(label) == 1).collect()\n",
                "  fig, ax = plt.subplots()\n",
                "  fig.set_size_inches(18.5, 10.5)\n",
                "\n",
                "  flights_dict = defaultdict(int)\n",
                "  labels = []\n",
                "  counts = []\n",
                "\n",
                "  for row in problematic_flights:\n",
                "    flights_dict[row[\"ORIGIN\"]] += 1\n",
                "\n",
                "  for key in flights_dict:\n",
                "    single_origin_total_flights = data.filter(col(\"ORIGIN\") == key).count()\n",
                "    flights_dict[key] = flights_dict[key] / single_origin_total_flights * 100\n",
                "\n",
                "  for key in flights_dict:\n",
                "    condition = 5 if problem_to_solve == 'CANCELLED' else 1\n",
                "    if flights_dict[key] > condition:\n",
                "      labels.append(key)\n",
                "      counts.append(flights_dict[key])\n",
                "  labels.append(\"Majority\")\n",
                "  counts.append(1)\n",
                "\n",
                "  ax.bar(labels, counts)\n",
                "\n",
                "  ax.set_ylabel('Percentages')\n",
                "  ax.set_title('Problematic flights percentage per origin')\n",
                "\n",
                "  plt.show()\n",
                "\n",
                "\n",
                "def plot_problematic_flights_per_month_chart(data: ps.DataFrame, label: str):\n",
                "  problematic_flights = data.filter(col(label) == 1).collect()\n",
                "  fig, ax = plt.subplots()\n",
                "\n",
                "  flights_dict = defaultdict(int)\n",
                "  labels = []\n",
                "  counts = []\n",
                "\n",
                "  for row in problematic_flights:\n",
                "    month = parser.parse(row[\"FL_DATE\"]).month\n",
                "    flights_dict[month] += 1\n",
                "\n",
                "  for key in flights_dict:\n",
                "    condition_string = (\"-0\" + str(key) + \"-\") if key < 10 else (\"-\" + str(key) + \"-\")\n",
                "    single_month_total_flights = data.filter(col(\"FL_DATE\").contains(condition_string)).count()\n",
                "    flights_dict[key] = flights_dict[key] / single_month_total_flights * 100\n",
                "\n",
                "  for key in sorted(flights_dict):\n",
                "    labels.append(key)\n",
                "    counts.append(flights_dict[key])\n",
                "\n",
                "  ax.bar(labels, counts)\n",
                "\n",
                "  ax.set_ylabel('Percentages')\n",
                "  ax.set_title('Problematic flights percentage per month')\n",
                "\n",
                "  plt.show()\n",
                "\n",
                "\n",
                "def plot_problematic_flights_per_weekday_chart(data: ps.DataFrame, label: str):\n",
                "  problematic_flights = data.filter(col(label) == 1).collect()\n",
                "  fig, ax = plt.subplots()\n",
                "\n",
                "  flights_dict = defaultdict(int)\n",
                "  labels = []\n",
                "  counts = []\n",
                "\n",
                "  for row in problematic_flights:\n",
                "    weekday = parser.parse(row[\"FL_DATE\"]).isoweekday()\n",
                "    flights_dict[weekday] += 1    \n",
                "\n",
                "  dates_frame = data.select(\"FL_DATE\").collect()\n",
                "\n",
                "  for key in flights_dict:\n",
                "    single_weekday_total_flights = 0\n",
                "\n",
                "    for row in dates_frame:\n",
                "      parsed_value = parser.parse(row[\"FL_DATE\"]).isoweekday()\n",
                "      if parsed_value == key:\n",
                "        single_weekday_total_flights += 1\n",
                "\n",
                "    flights_dict[key] = flights_dict[key] / single_weekday_total_flights * 100\n",
                "\n",
                "  for key in sorted(flights_dict):\n",
                "    labels.append(key)\n",
                "    counts.append(flights_dict[key])\n",
                "\n",
                "  ax.bar(labels, counts)\n",
                "\n",
                "  ax.set_ylabel('Percentages')\n",
                "  ax.set_title('Problematic flights percentage per weekday')\n",
                "\n",
                "  plt.show()\n",
                "\n",
                "\n",
                "def plot_problematic_flights_per_origin_box(data: ps.DataFrame, label: str):\n",
                "  problematic_flights = data.filter(col(label) == 1).collect()\n",
                "  fig, ax = plt.subplots()\n",
                "\n",
                "  flights_dict = defaultdict(int)\n",
                "  labels = []\n",
                "  counts = []\n",
                "\n",
                "  for row in problematic_flights:\n",
                "    flights_dict[row[\"ORIGIN\"]] += 1\n",
                "\n",
                "  for key in flights_dict:\n",
                "    single_origin_total_flights = data.filter(col(\"ORIGIN\") == key).count()\n",
                "    flights_dict[key] = flights_dict[key] / single_origin_total_flights * 100\n",
                "\n",
                "  for key in flights_dict:\n",
                "    labels.append(key)\n",
                "    counts.append(flights_dict[key])\n",
                "\n",
                "  ax.boxplot(counts)\n",
                "\n",
                "  ax.set_ylabel('Percentages')\n",
                "  ax.set_title('Problematic flights percentage per origin')\n",
                "\n",
                "  plt.show()\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### Dataset Reading"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "start_time = tm.time()\n",
                "data = get_dataset(dataset_limit, use_all_dataset_frames).cache()\n",
                "\n",
                "finish_time = tm.time() - start_time\n",
                "print_and_save_time(\"Dataset reading concluded: \" +\n",
                "                    str(finish_time) + \" seconds\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### Null Rows Dropping"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "#Various tests showed that the rows with null values are extremely rare, so removing them form the dataset will not bring any significative loss of informations.\n",
                "\n",
                "common_start_time = tm.time()\n",
                "\n",
                "data = data.dropna(how='any')\n",
                "print(\"Dataframe rows after NaN dropping: \" + str(data.count()))\n",
                "\n",
                "null_removal_finish_time = tm.time() - common_start_time\n",
                "print_and_save_time(\"Null values removal concluded: \" +\n",
                "                    str(null_removal_finish_time) + \" seconds\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### Data Analysis"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "plot_balancing_chart(data, problem_to_solve)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "plot_problematic_flights_per_carrier_chart(data, problem_to_solve)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "plot_problematic_flights_per_origin_box(data, problem_to_solve)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "#Based on the box plot, for the CANCELLED problem, we decided to aggregate in one column the airports with a percentage lower than 5 to improve chart readability.\n",
                "#For the DIVERTED problem, the value 1 is enough.\n",
                "\n",
                "plot_problematic_flights_per_origin_chart(data, problem_to_solve)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "plot_problematic_flights_per_month_chart(data, problem_to_solve)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "plot_problematic_flights_per_weekday_chart(data, problem_to_solve)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "From the various charts plotted, we can see that, despite some outliers, the features don't seem to show any significant correlation with the cancellation or diversion of the flights.\n",
                "The model will probably have a hard time differentiating between problematic and regular flights, due to the scarce impact of the features to determine the result of a flight."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### Dataframe Balancing"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "#Due to the really low amount of problematic flights found in the dataset, the training set would be really\n",
                "#unbalanced and probably lead to poor results, so to balance it we proceeded using the undersampling technique, limiting the number of normal flights to be taken.\n",
                "\n",
                "start_time = tm.time()\n",
                "irregular_flights = data.filter(col(problem_to_solve) == 1)\n",
                "\n",
                "regular_flights = data.filter(col(problem_to_solve) == 0).limit(irregular_flights.count())\n",
                "\n",
                "flight_ids = irregular_flights.rdd.map(lambda x: x.id).collect() + \\\n",
                "    regular_flights.rdd.map(lambda x: x.id).collect()\n",
                "\n",
                "data = data.filter(data.id.isin(flight_ids)).orderBy(rand())\n",
                "print(\"Balanced dataframe rows: \" + str(data.count()))\n",
                "\n",
                "finish_time = tm.time() - start_time\n",
                "print_and_save_time(\"Dataset balancing concluded: \" +\n",
                "                    str(finish_time) + \" seconds\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "plot_balancing_chart(data, problem_to_solve)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### Column Conversions"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "#The string and timestamps columns have been converted into float numbers, to keep the values between 0 and 1 various multipliers have been used.\n",
                "\n",
                "columns_start_time = tm.time()\n",
                "\n",
                "@udf(returnType=DoubleType())\n",
                "def str_to_float(s: str):\n",
                "  encoding = \"utf-8\"\n",
                "  b = s.encode(encoding)\n",
                "  return float(crc32(b) & 0xffffffff) / 2**32\n",
                "\n",
                "date_multiplier: float = 1 / 365\n",
                "@udf(returnType=DoubleType())\n",
                "def date_to_day_of_year(date_string) -> float:\n",
                "  date = dt.strptime(date_string, \"%Y-%m-%d\")\n",
                "  day = date.timetuple().tm_yday - 1\n",
                "  return day * date_multiplier\n",
                "\n",
                "@udf(returnType=DoubleType())\n",
                "def time_to_interval(time) -> float:\n",
                "  t = int(float(time))\n",
                "  h = t // 100\n",
                "  m = t % 100\n",
                "  t = h * 60 + m\n",
                "  return float(t / 1140)\n",
                "\n",
                "distance_multiplier = float(1) / float(max_distance)\n",
                "\n",
                "data = data.select(\n",
                "  (data.CANCELLED.cast('double')).alias(\"CANCELLED\"),\n",
                "  (data.DIVERTED.cast('double')).alias(\"DIVERTED\"),\n",
                "  str_to_float(data.OP_CARRIER).alias(\"OP_CARRIER\"),\n",
                "  str_to_float(data.ORIGIN).alias(\"ORIGIN\"),\n",
                "  str_to_float(data.DEST).alias(\"DEST\"),\n",
                "  date_to_day_of_year(data.FL_DATE).alias(\"FL_DATE\"),\n",
                "  time_to_interval(data.CRS_DEP_TIME).alias(\"CRS_DEP_TIME\"),\n",
                "  time_to_interval(data.CRS_ARR_TIME).alias(\"CRS_ARR_TIME\"),\n",
                "  time_to_interval(data.CRS_ELAPSED_TIME).alias(\"CRS_ELAPSED_TIME\"),\n",
                "  (data.DISTANCE.cast('double') * distance_multiplier).alias(\"DISTANCE\"),\n",
                "  data.id\n",
                ")\n",
                "\n",
                "data.count()\n",
                "\n",
                "columns_finish_time = tm.time() - columns_start_time\n",
                "print_and_save_time(\"Columns conversion concluded: \" +\n",
                "                    str(columns_finish_time) + \" seconds\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### Z Score Normalization"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "#The various columns have been normalized using the z-score method, subtracting every value for the mean of its column and dividing by the column standard deviation.\n",
                "\n",
                "z_start_time = tm.time()\n",
                "column_list = data.columns\n",
                "column_mean_dict = dict()\n",
                "column_stddv_dict = dict()\n",
                "\n",
                "for c in column_list:\n",
                "    column_mean_dict[c] = data.agg({c: 'mean'}).head()[0]\n",
                "    column_stddv_dict[c] = data.agg({c: 'stddev'}).head()[0]\n",
                "\n",
                "data = data.select(\n",
                "  problem_to_solve,\n",
                "\n",
                "  ((data.OP_CARRIER - column_mean_dict[\"OP_CARRIER\"]) / column_stddv_dict[\"OP_CARRIER\"]).alias('OP_CARRIER'),\n",
                "\n",
                "  ((data.ORIGIN - column_mean_dict[\"ORIGIN\"]) / column_stddv_dict[\"ORIGIN\"]).alias('ORIGIN'),\n",
                "\n",
                "  ((data.DEST - column_mean_dict[\"DEST\"]) / column_stddv_dict[\"DEST\"]).alias('DEST'),\n",
                "\n",
                "  ((data.FL_DATE - column_mean_dict[\"FL_DATE\"]) / column_stddv_dict[\"FL_DATE\"]).alias('FL_DATE'),\n",
                "\n",
                "  ((data.CRS_DEP_TIME - column_mean_dict[\"CRS_DEP_TIME\"]) / column_stddv_dict[\"CRS_DEP_TIME\"]).alias('CRS_DEP_TIME'),\n",
                "\n",
                "  ((data.CRS_ARR_TIME - column_mean_dict[\"CRS_ARR_TIME\"]) /  column_stddv_dict[\"CRS_ARR_TIME\"]).alias('CRS_ARR_TIME'),\n",
                "\n",
                "  ((data.CRS_ELAPSED_TIME - column_mean_dict[\"CRS_ELAPSED_TIME\"]) / column_stddv_dict[\"CRS_ELAPSED_TIME\"]).alias('CRS_ELAPSED_TIME'),\n",
                "\n",
                "  ((data.DISTANCE - column_mean_dict[\"DISTANCE\"]) / column_stddv_dict[\"DISTANCE\"]).alias('DISTANCE'),\n",
                "\n",
                "  data.id\n",
                ")\n",
                "\n",
                "data.count()\n",
                "\n",
                "z_finish_time = tm.time() - z_start_time\n",
                "print_and_save_time(\"Z score normalization concluded: \" +\n",
                "                    str(z_finish_time) + \" seconds\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### Preprocessed dataset Saving/Loading"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def save_dataset(data):\n",
                "  data.write.format('csv').option('header', True).mode('overwrite').option(\n",
                "      'sep', ',').save('./preprocessed/' + problem_to_solve)\n",
                "  print('Preprocessed dataset saved')\n",
                "\n",
                "save_dataset(data)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def load_dataset():\n",
                "    data = spark.read.format(\"csv\") \\\n",
                "        .option(\"header\", True) \\\n",
                "        .load('./preprocessed/' + problem_to_solve)\n",
                "\n",
                "    print('Preprocessed dataset loaded')\n",
                "    return data\n",
                "\n",
                "\n",
                "if load_cached:\n",
                "    data = load_dataset().cache()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### Splitting into Folds"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "#During the main phases of preprocessing the Dataframe structure have been preferred, to use the columns name notation and the sql functions to perform transformations.\n",
                "#The training part though found the RDD data structures to be more suitable for the tasks required, so a conversion has been accomplished.\n",
                "\n",
                "start_time = tm.time()\n",
                "folds: list[RDD] = []\n",
                "\n",
                "def format_rdd(rdd: RDD) -> RDD:\n",
                "    return rdd.map(lambda x: (float(x[0]), [float(y) for y in x[1:]]))\n",
                "\n",
                "temp = data\n",
                "\n",
                "k_elements_half_number = math.floor((temp.count() / fold_number) / 2)\n",
                "\n",
                "i = 0\n",
                "while i < fold_number:\n",
                "    k_positives = temp.where(\n",
                "        col(problem_to_solve) == 1).limit(k_elements_half_number)\n",
                "\n",
                "    k_negatives = temp.where(\n",
                "        col(problem_to_solve) == 0).limit(k_elements_half_number)\n",
                "\n",
                "    k_ids = k_positives.rdd.map(lambda x: x.id).collect() + \\\n",
                "        k_negatives.rdd.map(lambda x: x.id).collect()\n",
                "\n",
                "    k_sample = temp.filter(temp.id.isin(k_ids))\n",
                "    k_sample = k_sample.drop(k_sample.id)\n",
                "\n",
                "    k_sample = format_rdd(k_sample.rdd)\n",
                "\n",
                "    folds.append(k_sample)\n",
                "    temp = temp.filter(~temp.id.isin(k_ids))\n",
                "\n",
                "    print(\"Split \" + str(i + 1) + \" of \" + str(fold_number) + \" completed\")\n",
                "    print(\"Dataframe rows: \" + str(temp.count()))\n",
                "    i += 1\n",
                "\n",
                "finish_time = tm.time() - start_time\n",
                "print_and_save_time(\"Dataset splitting concluded: \" +\n",
                "                    str(finish_time) + \" seconds\")\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### Bonus: Pandas"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "#To make a comparison between PySpark parallel processing and a normal sequential data processing, dataset loading and preprocessing has been performed also with the Pandas library.\n",
                "\n",
                "def pandas_save_dataset(data):\n",
                "    data.to_csv(path_or_buf=path + '/' + 'preprocessed.csv', index=False)\n",
                "    print('Preprocessed dataset saved')\n",
                "\n",
                "# Data Load\n",
                "\n",
                "files = os.listdir(path)\n",
                "data = pd.DataFrame()\n",
                "\n",
                "for f in files:\n",
                "    if f.endswith('.csv'):\n",
                "        frame = pd.read_csv(filepath_or_buffer=path +\n",
                "                            '/' + f, usecols=columns_to_get)\n",
                "        frame.sample(frac=1)\n",
                "        frame = frame.head(dataset_limit)\n",
                "        data = pd.concat([data, frame])\n",
                "\n",
                "data = data.dropna(how='any', axis='index')\n",
                "print(\"Dataset acquisition completed\")\n",
                "\n",
                "# Problem Selection\n",
                "\n",
                "irregulars = data.loc[data[problem_to_solve] == 1]\n",
                "regulars = data.loc[data[problem_to_solve] == 0]\n",
                "\n",
                "data = pd.concat([regulars.sample(len(irregulars)), irregulars]).sample(frac=1)\n",
                "\n",
                "oppositeIndex = 'DIVERTED' if problem_to_solve == 'CANCELLED' else 'CANCELLED'\n",
                "data = data.drop(oppositeIndex, axis=1)\n",
                "print(\"Dataset balancing completed\")\n",
                "\n",
                "# Names Conversion\n",
                "\n",
                "def str_to_float(s: str):\n",
                "    encoding = \"utf-8\"\n",
                "    b = s.encode(encoding)\n",
                "    return float(crc32(b) & 0xffffffff) / 2**32\n",
                "\n",
                "for c in ['OP_CARRIER', 'ORIGIN', 'DEST']:\n",
                "    data[c] = data[c].apply(str_to_float)\n",
                "\n",
                "# Dates Conversion\n",
                "\n",
                "multiplier: float = 1 / 365\n",
                "\n",
                "def date_to_day_of_year(date_string) -> float:\n",
                "    date = dt.strptime(date_string, \"%Y-%m-%d\")\n",
                "    day = date.timetuple().tm_yday - 1\n",
                "    return day * multiplier\n",
                "\n",
                "data[\"FL_DATE\"] = data[\"FL_DATE\"].apply(date_to_day_of_year)\n",
                "\n",
                "# Time Conversion\n",
                "    \n",
                "def time_to_interval(time) -> float:\n",
                "    t = int(float(time))\n",
                "    h = t // 100\n",
                "    m = t % 100\n",
                "    t = h * 60 + m\n",
                "    return float(t / 1140)\n",
                "\n",
                "for c in [\"CRS_DEP_TIME\", \"CRS_ARR_TIME\", \"CRS_ELAPSED_TIME\"]:\n",
                "    data[c] = data[c].apply(time_to_interval)\n",
                "\n",
                "# Distance Conversion\n",
                "    \n",
                "multiplier: float = float(1) / float(max_distance)\n",
                "\n",
                "data[\"DISTANCE\"] = data[\"DISTANCE\"].apply(lambda x: x * multiplier)\n",
                "\n",
                "print(\"Dataset conversions completed\")\n",
                "\n",
                "#Z-score normalization\n",
                "\n",
                "def z_score_normalize(x, m, s) -> float:\n",
                "    return (x - m) / s\n",
                "\n",
                "column_list = list(data)\n",
                "column_list.remove(problem_to_solve)\n",
                "\n",
                "for c in column_list:\n",
                "    column_mean = data[c].mean()\n",
                "    column_stddv = data[c].std()\n",
                "    data[c] = data[c].apply(z_score_normalize, args=(column_mean, column_stddv))\n",
                "\n",
                "print(\"Dataset normalization completed\")\n",
                "# Create Folds\n",
                "\n",
                "folds = []\n",
                "\n",
                "data = data.drop_duplicates()\n",
                "\n",
                "irregulars = data.loc[data[problem_to_solve] == 1]\n",
                "regulars = data.loc[data[problem_to_solve] == 0]\n",
                "\n",
                "k_elements_half_number = round((len(data) / fold_number) / 2)\n",
                "\n",
                "for i in range(1, fold_number + 1):\n",
                "    k_irregulars_sample = irregulars.head(k_elements_half_number)\n",
                "    k_regulars_sample = regulars.head(k_elements_half_number)\n",
                "    k_sample = pd.concat([k_irregulars_sample, k_regulars_sample])\n",
                "\n",
                "    folds.append(k_sample)\n",
                "    irregulars = irregulars.drop(k_irregulars_sample.index)\n",
                "    regulars = regulars.drop(k_regulars_sample.index)\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Models"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Generic Functions"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def sigmoid(x):\n",
                "    '''\n",
                "    Calculates the sigmoid of the given data\n",
                "    '''\n",
                "    g = 1.0 / (1.0 + np.exp(-x))\n",
                "    return g\n",
                "\n",
                "def binary_cross_entropy(y, y_label, w, l2):\n",
                "    '''\n",
                "    Calculates the binary cross entropy loss of the calculated y and the given y_label\n",
                "    '''\n",
                "    loss = -np.mean(y_label*(np.log(y)) + (1-y_label)\n",
                "                    * np.log(1-y)) + regularize(w, l2)\n",
                "    return loss\n",
                "\n",
                "def regularize(W, l2):\n",
                "    '''\n",
                "    Calculates the regularization term for the loss\n",
                "    '''\n",
                "    return (l2 / 2) * np.sum(np.square(W))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Parallel Model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "@dataclass\n",
                "class ParallelLogisticRegression:\n",
                "    iterations: int\n",
                "    learning_rate: float\n",
                "    batch_size: int\n",
                "    l2: float\n",
                "    W: Broadcast\n",
                "    b: float\n",
                "\n",
                "def parallel_initialize(self: ParallelLogisticRegression, feature_number: int):\n",
                "    self.W = context.broadcast(np.random.rand(feature_number))\n",
                "    self.b = np.random.rand()\n",
                "\n",
                "def parallel_train(self: ParallelLogisticRegression, data: RDD):\n",
                "\n",
                "    if self.batch_size != 0:\n",
                "        num_chunks = data.count() // self.batch_size\n",
                "        chunk_percent = 1/num_chunks\n",
                "        batches = data.randomSplit([chunk_percent] * num_chunks)\n",
                "    else:\n",
                "        batches = [data]\n",
                "\n",
                "    losses = []\n",
                "    gradients = []\n",
                "\n",
                "    for _ in range(self.iterations):\n",
                "        _losses = []\n",
                "        _gradients = []\n",
                "\n",
                "        for batch in batches:\n",
                "            batch = batch.cache()\n",
                "            Y = parallel_evaluate(self, batch)\n",
                "            _losses.append(parallel_binary_cross_entropy(self, batch.map(lambda x: x[0]).zip(Y)))\n",
                "            (dW, db) = parallel_gradient(self, batch, Y)\n",
                "            _gradients.append(dW)\n",
                "            parallel_update(self, dW, db)\n",
                "        losses.append(np.mean(_losses))\n",
                "        gradients.append(np.mean(_gradients))\n",
                "\n",
                "    return (losses, gradients)\n",
                "\n",
                "\n",
                "def parallel_evaluate(self: ParallelLogisticRegression, X: RDD) -> RDD:\n",
                "    Z: RDD = X.map(lambda x: np.dot(x[1], self.W.value))\n",
                "    Z = Z.map(lambda x: sigmoid(x))\n",
                "    return Z\n",
                "\n",
                "def parallel_binary_cross_entropy(self: ParallelLogisticRegression, X_Y: RDD)-> float:\n",
                "    L: RDD = X_Y.map(lambda y: y[0] * np.log(y[1]) + (1 - y[0]) * np.log(1 -  y[1]))\n",
                "    return -L.reduce(lambda a, b: a + b)/L.count() + regularize(self.W.value, self.l2)\n",
                "\n",
                "def parallel_gradient(self: ParallelLogisticRegression, X: RDD, Y: RDD)-> tuple[np.ndarray, np.ndarray]:\n",
                "    m = X.count()\n",
                "    dw = X.zip(Y).map(lambda x: np.dot((x[1] - x[0][0]), x[0][1])).reduce(lambda a, b: (a + b) * 1/m + self.W.value * self.l2)\n",
                "    db = X.zip(Y).map(lambda x: x[1] - x[0][0]).reduce(lambda a, b: a + b) * 1/m\n",
                "    return dw, db\n",
                "\n",
                "def parallel_update(self: ParallelLogisticRegression, dW: list[float], db: float):\n",
                "    self.W = context.broadcast(self.W.value - self.learning_rate * dW)\n",
                "    self.b = self.b - self.learning_rate * db"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Serial Model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "class SerialLogisticRegression():\n",
                "    def __init__(self, iterations: int, learning_rate: float, batch_size: int, l2: float):\n",
                "        self.iterations = iterations\n",
                "        self.learning_rate = learning_rate\n",
                "        self.batch_size = batch_size\n",
                "        self.l2 = l2\n",
                "\n",
                "    def initialize(self, columns_number):\n",
                "        self.W = np.random.rand(columns_number)\n",
                "        self.b = np.random.rand()\n",
                "\n",
                "    def evaluate(self, X):\n",
                "        Z = np.dot(X, self.W) + self.b\n",
                "        Z = sigmoid(Z)\n",
                "        return Z\n",
                "\n",
                "    def gradient(self, X, Y, Y_label):\n",
                "        '''\n",
                "        Calculates the gradient w.r.t weights and bias\n",
                "        '''\n",
                "\n",
                "        # Number of training examples.\n",
                "        m = X.shape[0]\n",
                "\n",
                "        # Gradient of loss w.r.t weights with regularization\n",
                "        dw = (1/m)*np.dot(X.T, (Y - Y_label)) + self.l2 * self.W\n",
                "\n",
                "        # Gradient of loss w.r.t bias with regularization\n",
                "        db = (1/m)*np.sum((Y - Y_label))\n",
                "\n",
                "        return dw, db\n",
                "\n",
                "    def update(self, dW, db):\n",
                "        self.W = self.W - self.learning_rate * dW\n",
                "        self.b = self.b - self.learning_rate * db\n",
                "\n",
                "    def train(self, X, Y_labels):\n",
                "        losses = []\n",
                "        gradients = []\n",
                "\n",
                "        if self.batch_size == 0:\n",
                "            self.batch_size = X.shape[0]\n",
                "\n",
                "        for _ in range(self.iterations):\n",
                "            _losses = []\n",
                "            _gradients = []\n",
                "            for b in range(X.shape[0]//self.batch_size):\n",
                "                b_X = X[b*self.batch_size:b*self.batch_size+self.batch_size, :]\n",
                "                b_Y_labels = Y_labels[b*self.batch_size:b *\n",
                "                                      self.batch_size+self.batch_size]\n",
                "                Y = self.evaluate(b_X)\n",
                "                _losses.append(binary_cross_entropy(\n",
                "                    Y, b_Y_labels, self.W, self.l2))\n",
                "                (dW, db) = self.gradient(b_X, Y, b_Y_labels)\n",
                "                _gradients.append(dW)\n",
                "                self.update(dW, db)\n",
                "            losses.append(np.mean(_losses))\n",
                "            gradients.append(np.mean(_gradients))\n",
                "\n",
                "        return (losses, gradients)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Experiments\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def describe(labels: RDD, predictions: RDD):\n",
                "    zipped = labels.zip(predictions)\n",
                "    tn = zipped.filter(lambda x: round(x[0]) == 0 and round(x[1]) == 0).count()\n",
                "    tp = zipped.filter(lambda x: round(x[0]) == 1 and round(x[1]) == 1).count()\n",
                "    fn = zipped.filter(lambda x: round(x[0]) == 1 and round(x[1]) == 0).count()\n",
                "    fp = zipped.filter(lambda x: round(x[0]) == 0 and round(x[1]) == 1).count()\n",
                "    precision = tp / (tp + fp)\n",
                "    recall = tp / (tp + fn)\n",
                "    f1 = 2 * (precision * recall) / (precision + recall)\n",
                "    acc = (tp + tn)/(tp + tn + fn + fp)\n",
                "    specificity = tn/(tn+fp)\n",
                "    return pd.DataFrame([[tn, tp, fn, fp, precision, recall, f1, acc, specificity]], columns=['TN', 'TP', 'FN', 'FP', 'Precision', 'Recall', 'F1', 'Accuracy', 'Specificity'])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def make_roc(labels: RDD, results: RDD):\n",
                "    labels = labels.collect()\n",
                "    results = results.collect()\n",
                "    labels_and_results = sorted(list(zip(labels, results)), key=lambda x: x[1])\n",
                "\n",
                "    labels_by_weights = np.array([k for (k, _) in labels_and_results])\n",
                "\n",
                "    length = labels_by_weights.size\n",
                "\n",
                "    true_positives = labels_by_weights.cumsum()\n",
                "\n",
                "    num_positive = true_positives[-1]\n",
                "\n",
                "    false_positives = np.arange(1.0, length + 1, 1.) - true_positives\n",
                "\n",
                "    true_positives_rate = true_positives / num_positive\n",
                "    false_positives_rate = false_positives / (length - num_positive)\n",
                "\n",
                "    fig, ax = plt.subplots()\n",
                "    ax.set_xlim(-.05, 1.05), ax.set_ylim(-.05, 1.05)\n",
                "    ax.set_ylabel('True Positive Rate (Sensitivity)')\n",
                "    ax.set_xlabel('False Positive Rate (1 - Specificity)')\n",
                "    plt.plot(false_positives_rate, true_positives_rate,\n",
                "             color='#8cbfd0', linestyle='-', linewidth=3.)\n",
                "    plt.plot((0., 1.), (0., 1.), linestyle='--',\n",
                "             color='#d6ebf2', linewidth=2.)\n",
                "    plt.show()\n",
                "\n",
                "def plot_loss_gradient(iterations, train_losses, gradients):\n",
                "    fig, ax = plt.subplots()\n",
                "    ax.set_xlabel('Iterations')\n",
                "    ax.set_ylabel('Loss/Gradient')\n",
                "    ax.plot(range(iterations), train_losses, label='Loss')\n",
                "    ax.plot(range(iterations), gradients, label='Gradient')\n",
                "    ax.grid()\n",
                "    ax.legend()\n",
                "\n",
                "    fig.clear()\n",
                "    plt.close()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Hyperparameters Tuning"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "grid: dict[str, list] = { 'iter': [10, 20, 50], 'lr': [0.001, 0.01, 0.1], 'l2': [1, 0.1, 0.01]}"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### K-Fold Cross Validation\n",
                "The following code defines a base class with train and evaluation methods to apply the K-Fold Cross Validation to each model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import itertools\n",
                "\n",
                "class Tuner:\n",
                "    def __init__(self, grid: dict, model_factory) -> None:\n",
                "        self.params = list(itertools.product(*grid.values()))\n",
                "        self.model_factory = model_factory\n",
                "\n",
                "    def search(self, input: list[RDD]):\n",
                "        models = dict[float, (list, KFoldTrainer)]()\n",
                "        for i in self.params:\n",
                "            model: KFoldTrainer = self.model_factory(*i)\n",
                "            test_loss, train_losses = model.train(input)\n",
                "            print(\"Completed configuration \" + '|'.join(map(lambda x: str(x), i)))\n",
                "            models[test_loss] = (train_losses, model)\n",
                "        lowest = min(list(models.keys()))\n",
                "        return (lowest, *models.get(lowest))\n",
                "\n",
                "class KFoldTrainer:\n",
                "    def __init__(self, iterations, lr, l2, batch_size):\n",
                "        self.iterations = iterations\n",
                "        self.lr = lr\n",
                "        self.l2 = l2\n",
                "        self.batch_size = batch_size\n",
                "\n",
                "    def train(self, data: list[RDD]):\n",
                "        test_set = data[0]\n",
                "        rest = data[1:]\n",
                "        train_losses = []\n",
                "        for i, fold in enumerate(rest):\n",
                "            evaluation_set = fold\n",
                "            remaining_folds= rest[:i] + rest[i + 1:]\n",
                "            train_set = remaining_folds[0]\n",
                "            for train_fold in remaining_folds[1:]:\n",
                "                train_set = train_set.union(train_fold)\n",
                "            self.train_impl(train_fold)\n",
                "            loss = self.test_impl(evaluation_set)\n",
                "            train_losses.append(loss)\n",
                "        test_loss = self.test_impl(test_set)\n",
                "        return test_loss, train_losses"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# COMPARARE WEIGHTS"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "class ParallelModelEvaluator(KFoldTrainer):\n",
                "    def __init__(self, iterations, lr, l2, batch_size):\n",
                "        super().__init__(iterations, lr, l2, batch_size)\n",
                "        self.model = ParallelLogisticRegression(self.iterations, self.lr, self.batch_size, self.l2, None, None)\n",
                "        parallel_initialize(self.model, 8)\n",
                "\n",
                "    def train_impl(self, train_data: RDD):\n",
                "        return parallel_train(self.model, train_data)\n",
                "    \n",
                "    def test_impl(self, test_data: RDD):\n",
                "        value: RDD = parallel_evaluate(self.model, test_data)\n",
                "        return parallel_binary_cross_entropy(self.model, test_data.map(lambda x: x[0]).zip(value))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "data = [np.array([x+1, x+2, x+3, x+12]) for x in [1,2,3,4]]\n",
                "data = pd.DataFrame(data, columns= ['n_iters', 'lr', 'alpha', 'cost'])\n",
                "\n",
                "import plotly.graph_objects as go\n",
                "\n",
                "fig = go.Figure(data=[go.Scatter3d(\n",
                "    x=data['lr'],\n",
                "    y=data['l2'],\n",
                "    z=data['iterations'],\n",
                "    mode='markers',\n",
                "    text=('lr', 'l2', 'iterations'),\n",
                "    marker=dict(\n",
                "        color=data['cost'], \n",
                "        colorscale='Viridis', \n",
                "        #opacity=1.0,\n",
                "        #size=14, colorbar=dict(thickness=20)\n",
                "    )\n",
                ")])\n",
                "\n",
                "\n",
                "# tight layout\n",
                "fig.update_layout(\n",
                "    autosize=False,\n",
                "    width=600, \n",
                "    height=600,\n",
                "    title='Hyperparameters space', \n",
                "    margin=dict(l=0, r=0, b=0, t=0),\n",
                "    scene=dict(\n",
                "        xaxis_title='learning rate',\n",
                "        yaxis_title='alpha',\n",
                "        zaxis_title='no. iters',\n",
                "    ),\n",
                ")\n",
                "\n",
                "fig.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Sequential Implementation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "class SequentialEvaluator(KFoldTrainer):\n",
                "    def __init__(self, iterations, lr, l2, batch_size):\n",
                "        super().__init__(iterations, lr, l2, batch_size)\n",
                "        self.model = SerialLogisticRegression(self.iterations, self.lr, self.batch_size, self.l2)\n",
                "        self.model.initialize(8)\n",
                "\n",
                "    def train_impl(self, train_data: RDD):\n",
                "        return self.model.train(np.array(train_data.map(lambda x: x[1]).collect()), np.array(train_data.map(lambda x: x[0]).collect()))\n",
                "\n",
                "    def test_impl(self, test_data: RDD):\n",
                "        res = self.model.evaluate(np.array(test_data.map(lambda x: x[1]).collect()))\n",
                "        return binary_cross_entropy(res, np.array(test_data.map(lambda x: x[0]).collect()), self.model.W, self.l2)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "e: SequentialEvaluator = SequentialEvaluator(10, 0.1, 0.1, 0)\n",
                "e.train(folds)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "t = Tuner(grid, lambda it, lr, l2: SequentialEvaluator(it, lr, l2, 0))\n",
                "test_loss, train_losses, best_model = t.search(folds)\n",
                "print(\"Iterations {} Lr {} L2 {} Batch {} Loss {}\".format(best_model.iterations, best_model.lr, best_model.l2, best_model.batch_size, test_loss))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "t = Tuner(grid, lambda it, lr, l2: ParallelModelEvaluator(it, lr, l2, 0))\n",
                "test_loss, train_losses, best_model = t.search(folds)\n",
                "print(\"Iterations {} Lr {} L2 {} Batch {} Loss {}\".format(best_model.iterations, best_model.lr, best_model.l2, best_model.batch_size, test_loss))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "labels = folds[0].map(lambda x: x[0]).coalesce(1)\n",
                "input = np.array(folds[0].collect())\n",
                "predictions = context.parallelize(e.model.evaluate(input)).coalesce(1)\n",
                "describe(labels, predictions)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "make_roc(labels, predictions)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Pyspark ML Implementations\n",
                "The following cells use some state-of-the-art models provided by the Pyspark ML library, in particular their implementation of the Logistic Regression and Decision Tree models.\n",
                "\n",
                "They should be most performant implementations of a distributed machine learning model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from pyspark.ml.feature import VectorAssembler\n",
                "\n",
                "ml_data = data.select([col(c).cast('float').alias(c) if c != problem_to_solve else col(c).cast('float').alias('label') for c in data.columns[:-1]])\n",
                "\n",
                "assembler = VectorAssembler(inputCols=ml_data.columns[1:-1], outputCol='features')\n",
                "\n",
                "ml_data = assembler.transform(ml_data).select(['features', 'label'])\n",
                "\n",
                "train_set, test_set = ml_data.randomSplit([0.9, 0.1])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
                "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
                "\n",
                "class SparkMLTuner:\n",
                "    def __init__(self, estimator, grid_builder: ParamGridBuilder, num_fold: int):\n",
                "        self.evaluator = BinaryClassificationEvaluator()\n",
                "        self.cv = CrossValidator(estimator=estimator, estimatorParamMaps=grid_builder.build(), evaluator=self.evaluator, numFolds=num_fold)\n",
                "\n",
                "    def train(self, data: ps.DataFrame):\n",
                "        self.model = self.cv.fit(data)\n",
                "        return self.model.bestModel.params\n",
                "\n",
                "    def test(self, data: ps.DataFrame):\n",
                "        predictions = self.model.transform(data)\n",
                "        return predictions, self.evaluator.evaluate(predictions)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Logistic Regression"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from pyspark.ml.classification import LogisticRegression\n",
                "\n",
                "e = LogisticRegression(featuresCol='features', labelCol='label')\n",
                "g = ParamGridBuilder().addGrid(e.regParam, grid['l2']).addGrid(e.maxIter, grid['iter'])\n",
                "t1 = SparkMLTuner(e, g, 10)\n",
                "t1.train(train_set)\n",
                "predictions, loss = t1.test(test_set)\n",
                "\n",
                "labels = test_set.select(col('label')).rdd.map(lambda x: float(x[0]))\n",
                "predictions = predictions.select(col('prediction')).rdd.map(lambda x: float(x[0]))\n",
                "\n",
                "describe(labels, predictions)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "make_roc(labels, predictions)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Decision Tree"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from pyspark.ml.classification import DecisionTreeClassifier\n",
                "e = DecisionTreeClassifier(featuresCol='features', labelCol='label')\n",
                "g = ParamGridBuilder()\n",
                "t = SparkMLTuner(e, g, 10)\n",
                "t.train(train_set)\n",
                "predictions, loss = t.test(test_set)\n",
                "\n",
                "labels = test_set.select(col('label')).rdd.map(lambda x: float(x[0]))\n",
                "predictions = predictions.select(col('prediction')).rdd.map(lambda x: float(x[0]))\n",
                "\n",
                "describe(labels, predictions)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "make_roc(labels, predictions)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.10.4 64-bit",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.4"
        },
        "orig_nbformat": 4,
        "vscode": {
            "interpreter": {
                "hash": "5012df37ab392b9f7e40bd0f27b82c3885414c9b5e6b3ef97e27ea44f17725dd"
            }
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
