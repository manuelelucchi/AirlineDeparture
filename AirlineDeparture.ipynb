{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "!pip install numpy kaggle pandas pyspark findspark matplotlib scikit-learn plotly\n",
                "\n",
                "import os\n",
                "from kaggle.api.kaggle_api_extended import KaggleApi\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "from pyspark.sql.types import StructType, StructField, StringType, DoubleType, FloatType\n",
                "from pyspark.sql import SparkSession\n",
                "from pyspark.sql.functions import monotonically_increasing_id, col, udf, rand\n",
                "import matplotlib.pyplot as plt\n",
                "import math\n",
                "import pyspark.sql as ps\n",
                "from zlib import crc32\n",
                "import time as tm\n",
                "from datetime import datetime as dt\n",
                "from dateutil import parser\n",
                "import itertools\n",
                "from collections import defaultdict\n",
                "from dataclasses import dataclass\n",
                "from pyspark.sql import functions as F\n",
                "from pyspark.rdd import RDD\n",
                "from pyspark.broadcast import Broadcast\n",
                "import findspark"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "path = './data'\n",
                "worker_nodes = \"*\"\n",
                "problem_to_solve = 'DIVERTED'\n",
                "\n",
                "dataset_limit = 100000\n",
                "use_all_dataset_frames = True\n",
                "fold_number = 10\n",
                "load_cached = True\n",
                "\n",
                "def print_and_save_time(s: str):\n",
                "  f = open(\"./times.txt\", \"a\")\n",
                "  f.write(str(dt.now()) + \" - \" + s + \"\\n\")\n",
                "  f.close()\n",
                "  print(s)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Data Download"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "os.environ['KAGGLE_USERNAME'] = \"davidetricella\"\n",
                "os.environ['KAGGLE_KEY'] = \"e1ab3aae4a07f36b37a3a8bace74d9df\"\n",
                "\n",
                "\n",
                "dataset = 'yuanyuwendymu/airline-delay-and-cancellation-data-2009-2018'\n",
                "path = './data'"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def download_dataset():\n",
                "    if not os.path.isdir(path):\n",
                "        os.mkdir(path)\n",
                "    if not os.listdir(path):\n",
                "        try:\n",
                "            api = KaggleApi()\n",
                "            api.authenticate()\n",
                "            api.dataset_download_files(dataset, path, unzip=True, quiet=False)\n",
                "        except:\n",
                "            print(\"Error downloading the dataset\")\n",
                "\n",
                "download_dataset()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Data Loading"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "dataframe_schema = StructType([\n",
                "    StructField('FL_DATE', StringType(), True),\n",
                "    StructField('OP_CARRIER', StringType(), True),\n",
                "    StructField('ORIGIN', StringType(), True),\n",
                "    StructField('DEST', StringType(), True),\n",
                "    StructField('CRS_DEP_TIME', StringType(), True),\n",
                "    StructField('CRS_ARR_TIME', StringType(), True),\n",
                "    StructField('CANCELLED', StringType(), True),\n",
                "    StructField('DIVERTED', StringType(), True),\n",
                "    StructField('CRS_ELAPSED_TIME', StringType(), True),\n",
                "    StructField('DISTANCE', StringType(), True)\n",
                "])\n",
                "\n",
                "columns_to_get = [\n",
                "    'FL_DATE',\n",
                "    'OP_CARRIER',\n",
                "    'ORIGIN',\n",
                "    'DEST',\n",
                "    'CRS_DEP_TIME',\n",
                "    'CRS_ARR_TIME',\n",
                "    'CANCELLED',\n",
                "    'DIVERTED',\n",
                "    'CRS_ELAPSED_TIME',\n",
                "    'DISTANCE'\n",
                "]\n",
                "\n",
                "#Rounded max distance between airports found in the dataset\n",
                "max_distance = 4970\n",
                "\n",
                "findspark.init()\n",
                "findspark.find()\n",
                "\n",
                "spark = SparkSession.builder \\\n",
                ".appName(\"Airline Departure\") \\\n",
                ".master('local[' + worker_nodes + ']') \\\n",
                ".getOrCreate()\n",
                "\n",
                "context = spark.sparkContext\n",
                "\n",
                "#The rows are loaded fom all files or only the first one with a limit value\n",
                "def get_dataset(limit: float = -1, allFrames: bool = True):\n",
                "    files = os.listdir(path)\n",
                "    big_frame = spark.createDataFrame(\n",
                "        spark.sparkContext.emptyRDD(), schema=dataframe_schema)\n",
                "    if not allFrames:\n",
                "        files = [files[0]]\n",
                "\n",
                "    for f in files:\n",
                "        if f.endswith('.csv'):\n",
                "            frame = spark.read.option(\"header\", True).csv(path + '/' + f)\n",
                "            frame = frame.select(columns_to_get)\n",
                "            frame = frame.orderBy(rand())\n",
                "\n",
                "            if limit != -1:\n",
                "                frame = frame.limit(limit)\n",
                "\n",
                "            big_frame = frame.union(big_frame)\n",
                "\n",
                "    big_frame = big_frame.withColumn(\n",
                "        \"id\", monotonically_increasing_id()).orderBy(rand())\n",
                "    big_frame.count()\n",
                "\n",
                "    return big_frame"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Preprocessing"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### Chart Plotting Definitions\n",
                "\n",
                "These are the defintions of the charts plotted during data analysis, the main chart used is the bar charts, to have a grasp of the \n",
                "various distributions of problematic flights regarding the most important columns chosen to train the model.\n",
                "During charts plotting, the data has been collected, taking advantage of the really low numbers of problematic flights in the dataset."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def month_key_to_label(key):\n",
                "  match key:\n",
                "    case 1:\n",
                "        return 'JAN'\n",
                "    case 2:\n",
                "        return 'FEB'\n",
                "    case 3:\n",
                "        return 'MAR'\n",
                "    case 4:\n",
                "        return 'APR'\n",
                "    case 5:\n",
                "        return 'MAY'\n",
                "    case 6:\n",
                "        return 'JUN'\n",
                "    case 7:\n",
                "        return 'JUL'\n",
                "    case 8:\n",
                "        return 'AUG'\n",
                "    case 9:\n",
                "        return 'SEP'\n",
                "    case 10:\n",
                "        return 'OCT'\n",
                "    case 11:\n",
                "        return 'NOV'\n",
                "    case 12:\n",
                "        return 'DEC'\n",
                "\n",
                "def plot_balancing_chart(data: ps.DataFrame, label: str):\n",
                "  total_positives = data.filter(col(label) == 1).count()\n",
                "  total_negatives = data.filter(col(label) == 0).count()\n",
                "  fig, ax = plt.subplots()\n",
                "\n",
                "  labels = ['REGULAR', label]\n",
                "  counts = [total_negatives, total_positives]\n",
                "  bar_colors = ['tab:blue', 'tab:red']\n",
                "\n",
                "  cont = ax.bar(labels, counts, color=bar_colors)\n",
                "  ax.bar_label(container=cont)\n",
                "\n",
                "  ax.set_ylabel('Counts')\n",
                "  ax.set_title(\"Regular flights and \" + problem_to_solve.lower() + \" flights counts\")\n",
                "\n",
                "  plt.show()\n",
                "\n",
                "def plot_problematic_flights_per_month_chart(data: ps.DataFrame, label: str):\n",
                "  problematic_flights = data.filter(col(label) == 1).collect()\n",
                "  fig, ax = plt.subplots()\n",
                "\n",
                "  flights_dict = defaultdict(int)\n",
                "  labels = []\n",
                "  counts = []\n",
                "\n",
                "  for row in problematic_flights:\n",
                "    month = parser.parse(row[\"FL_DATE\"]).month\n",
                "    flights_dict[month] += 1\n",
                "\n",
                "  for key in flights_dict:\n",
                "    condition_string = (\"-0\" + str(key) + \"-\") if key < 10 else (\"-\" + str(key) + \"-\")\n",
                "    single_month_total_flights = data.filter(col(\"FL_DATE\").contains(condition_string)).count()\n",
                "    flights_dict[key] = flights_dict[key] / single_month_total_flights * 100\n",
                "\n",
                "  for key in sorted(flights_dict):\n",
                "    labels.append(month_key_to_label(key))\n",
                "    counts.append(flights_dict[key])\n",
                "\n",
                "  ax.bar(labels, counts)\n",
                "\n",
                "  ax.set_ylabel('Percentages')\n",
                "  ax.set_xlabel('Months')\n",
                "  ax.set_title(problem_to_solve.lower().capitalize() + ' flights percentage per month')\n",
                "\n",
                "  plt.show()\n",
                "\n",
                "def plot_problematic_flights_per_weekday_chart(data: ps.DataFrame, label: str):\n",
                "  problematic_flights = data.filter(col(label) == 1).collect()\n",
                "  fig, ax = plt.subplots()\n",
                "\n",
                "  flights_dict = defaultdict(int)\n",
                "  days_dict = defaultdict(int)\n",
                "  labels = []\n",
                "  counts = []\n",
                "\n",
                "  for row in problematic_flights:\n",
                "    weekday = parser.parse(row[\"FL_DATE\"]).isoweekday()\n",
                "    flights_dict[weekday] += 1    \n",
                "\n",
                "  dates_frame = data.select(\"FL_DATE\").collect()\n",
                "\n",
                "  for row in dates_frame:\n",
                "      parsed_value = parser.parse(row[\"FL_DATE\"]).isoweekday()\n",
                "      days_dict[parsed_value] += 1\n",
                "\n",
                "  for key in flights_dict:\n",
                "    flights_dict[key] = flights_dict[key] / days_dict[key] * 100\n",
                "\n",
                "  for key in sorted(flights_dict):\n",
                "    labels.append(key)\n",
                "    counts.append(flights_dict[key])\n",
                "\n",
                "  ax.bar(labels, counts)\n",
                "\n",
                "  ax.set_ylabel('Percentages')\n",
                "  ax.set_xlabel('Weekdays')\n",
                "  ax.set_title(problem_to_solve.lower().capitalize() + ' flights percentage per weekday')\n",
                "\n",
                "  plt.show()\n",
                "\n",
                "def plot_problematic_flights_per_carrier_chart(data: ps.DataFrame, label: str):\n",
                "  selected_data = data.select((col(problem_to_solve).cast('double')).alias(problem_to_solve),\n",
                "                              (data.OP_CARRIER).alias(\"OP_CARRIER\"))\n",
                "  flight_counts = selected_data.groupBy(\"OP_CARRIER\").count().collect()\n",
                "  problematic_flights = selected_data.groupBy(\"OP_CARRIER\").sum(problem_to_solve).collect()\n",
                "\n",
                "  fig, ax = plt.subplots()\n",
                "\n",
                "  flights_dict = dict()\n",
                "  labels = []\n",
                "  counts = []\n",
                "\n",
                "  for i in range(len(problematic_flights)):\n",
                "    flights_dict[problematic_flights[i][0]] = problematic_flights[i][1] / flight_counts[i][1] * 100\n",
                "\n",
                "  mean = sum(flights_dict.values()) / len(flights_dict)\n",
                "\n",
                "  for key in flights_dict:\n",
                "    if flights_dict[key] > mean:\n",
                "      labels.append(key)\n",
                "      counts.append(flights_dict[key])\n",
                "  labels.append(\"Mean\")\n",
                "  counts.append(mean)\n",
                "\n",
                "  ax.bar(labels, counts)\n",
                "\n",
                "  ax.set_ylabel('Percentages')\n",
                "  ax.set_xlabel('Carrier codes')\n",
                "  ax.set_title(problem_to_solve.lower().capitalize() +\n",
                "               ' flights percentage per carrier')\n",
                "\n",
                "  plt.show()\n",
                "\n",
                "def plot_problematic_flights_per_origin_box(data: ps.DataFrame, label: str):\n",
                "  selected_data = data.select((col(problem_to_solve).cast('double')).alias(problem_to_solve),\n",
                "                              (data.ORIGIN).alias(\"ORIGIN\"))\n",
                "  flight_counts = selected_data.groupBy(\"ORIGIN\").count().collect()\n",
                "  problematic_flights = selected_data.groupBy(\n",
                "      \"ORIGIN\").sum(problem_to_solve).collect()\n",
                "\n",
                "  fig, ax = plt.subplots()\n",
                "\n",
                "  flights_dict = dict()\n",
                "  labels = []\n",
                "  counts = []\n",
                "\n",
                "  for i in range(len(problematic_flights)):\n",
                "    flights_dict[problematic_flights[i][0]\n",
                "                 ] = problematic_flights[i][1] / flight_counts[i][1] * 100\n",
                "\n",
                "  for key in flights_dict:\n",
                "    labels.append(key)\n",
                "    counts.append(flights_dict[key])\n",
                "\n",
                "  ax.boxplot(counts)\n",
                "\n",
                "  ax.set_ylabel('Percentages')\n",
                "  ax.set_xlabel('Airport codes')\n",
                "  ax.set_title(problem_to_solve.lower().capitalize() +\n",
                "               ' flights percentage per origin')\n",
                "\n",
                "  plt.show()\n",
                "\n",
                "def plot_problematic_flights_per_origin_chart(data: ps.DataFrame, label: str):\n",
                "  selected_data = data.select((col(problem_to_solve).cast('double')).alias(problem_to_solve),\n",
                "                              (data.ORIGIN).alias(\"ORIGIN\"))\n",
                "  flight_counts = selected_data.groupBy(\"ORIGIN\").count().collect()\n",
                "  problematic_flights = selected_data.groupBy(\n",
                "      \"ORIGIN\").sum(problem_to_solve).collect()\n",
                "\n",
                "  fig, ax = plt.subplots()\n",
                "  fig.set_size_inches(18.5, 10.5)\n",
                "\n",
                "  flights_dict = dict()\n",
                "  labels = []\n",
                "  counts = []\n",
                "\n",
                "  for i in range(len(problematic_flights)):\n",
                "    flights_dict[problematic_flights[i][0]\n",
                "                 ] = problematic_flights[i][1] / flight_counts[i][1] * 100\n",
                "\n",
                "  for key in flights_dict:\n",
                "    condition = 5 if problem_to_solve == 'CANCELLED' else 1\n",
                "    if flights_dict[key] > condition:\n",
                "      labels.append(key)\n",
                "      counts.append(flights_dict[key])\n",
                "  labels.append(\"Majority\")\n",
                "  counts.append(1)\n",
                "\n",
                "  ax.bar(labels, counts)\n",
                "\n",
                "  ax.set_ylabel('Percentages')\n",
                "  ax.set_title(problem_to_solve.lower().capitalize() +\n",
                "               ' flights percentage per origin')\n",
                "\n",
                "  plt.show()\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### Dataset Reading"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "start_time = tm.time()\n",
                "data = get_dataset(dataset_limit, use_all_dataset_frames).cache()\n",
                "\n",
                "finish_time = tm.time() - start_time\n",
                "print_and_save_time(\"Dataset reading concluded: \" +\n",
                "                    str(finish_time) + \" seconds\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### Null Rows Dropping\n",
                "\n",
                "Various tests showed that the rows with null values are extremely rare, so removing them form the dataset will not bring any significative loss of informations.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "common_start_time = tm.time()\n",
                "\n",
                "data = data.dropna(how='any')\n",
                "print(\"Dataframe rows after NaN dropping: \" + str(data.count()))\n",
                "\n",
                "null_removal_finish_time = tm.time() - common_start_time\n",
                "print_and_save_time(\"Null values removal concluded: \" +\n",
                "                    str(null_removal_finish_time) + \" seconds\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### Data Analysis"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "plot_balancing_chart(data, problem_to_solve)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "plot_problematic_flights_per_carrier_chart(data, problem_to_solve)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "plot_problematic_flights_per_origin_box(data, problem_to_solve)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Based on the box plot, for the CANCELLED problem, we decided to aggregate in one column the airports with a percentage lower than 5 to improve chart readability.\n",
                "For the DIVERTED problem, the value 1 is enough."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "plot_problematic_flights_per_origin_chart(data, problem_to_solve)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "plot_problematic_flights_per_month_chart(data, problem_to_solve)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "plot_problematic_flights_per_weekday_chart(data, problem_to_solve)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "From the various charts plotted, we can see that, despite some outliers, the features don't seem to show any significant correlation with the cancellation or diversion of the flights.\n",
                "The model will probably have a hard time differentiating between problematic and regular flights, due to the scarce impact of the features to determine the result of a flight."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### Dataframe Balancing\n",
                "\n",
                "Due to the really low amount of problematic flights found in the dataset, the training set would be really\n",
                "unbalanced and probably lead to poor results, so to balance it we proceeded using the undersampling technique, limiting the number of normal flights to be taken."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "start_time = tm.time()\n",
                "irregular_flights = data.filter(col(problem_to_solve) == 1)\n",
                "\n",
                "regular_flights = data.filter(col(problem_to_solve) == 0).limit(irregular_flights.count())\n",
                "\n",
                "flight_ids = irregular_flights.rdd.map(lambda x: x.id).collect() + \\\n",
                "    regular_flights.rdd.map(lambda x: x.id).collect()\n",
                "\n",
                "data = data.filter(data.id.isin(flight_ids)).orderBy(rand())\n",
                "print(\"Balanced dataframe rows: \" + str(data.count()))\n",
                "\n",
                "finish_time = tm.time() - start_time\n",
                "print_and_save_time(\"Dataset balancing concluded: \" +\n",
                "                    str(finish_time) + \" seconds\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "plot_balancing_chart(data, problem_to_solve)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### Column Conversions\n",
                "\n",
                "The string and timestamps columns have been converted into float numbers, to keep the values between 0 and 1 various multipliers have been used."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "columns_start_time = tm.time()\n",
                "\n",
                "@udf(returnType=DoubleType())\n",
                "def str_to_float(s: str):\n",
                "  encoding = \"utf-8\"\n",
                "  b = s.encode(encoding)\n",
                "  return float(crc32(b) & 0xffffffff) / 2**32\n",
                "\n",
                "date_multiplier: float = 1 / 365\n",
                "@udf(returnType=DoubleType())\n",
                "def date_to_day_of_year(date_string) -> float:\n",
                "  date = dt.strptime(date_string, \"%Y-%m-%d\")\n",
                "  day = date.timetuple().tm_yday - 1\n",
                "  return day * date_multiplier\n",
                "\n",
                "@udf(returnType=DoubleType())\n",
                "def time_to_interval(time) -> float:\n",
                "  t = int(float(time))\n",
                "  h = t // 100\n",
                "  m = t % 100\n",
                "  t = h * 60 + m\n",
                "  return float(t / 1140)\n",
                "\n",
                "distance_multiplier = float(1) / float(max_distance)\n",
                "\n",
                "data = data.select(\n",
                "  (data.CANCELLED.cast('double')).alias(\"CANCELLED\"),\n",
                "  (data.DIVERTED.cast('double')).alias(\"DIVERTED\"),\n",
                "  str_to_float(data.OP_CARRIER).alias(\"OP_CARRIER\"),\n",
                "  str_to_float(data.ORIGIN).alias(\"ORIGIN\"),\n",
                "  str_to_float(data.DEST).alias(\"DEST\"),\n",
                "  date_to_day_of_year(data.FL_DATE).alias(\"FL_DATE\"),\n",
                "  time_to_interval(data.CRS_DEP_TIME).alias(\"CRS_DEP_TIME\"),\n",
                "  time_to_interval(data.CRS_ARR_TIME).alias(\"CRS_ARR_TIME\"),\n",
                "  time_to_interval(data.CRS_ELAPSED_TIME).alias(\"CRS_ELAPSED_TIME\"),\n",
                "  (data.DISTANCE.cast('double') * distance_multiplier).alias(\"DISTANCE\"),\n",
                "  data.id\n",
                ")\n",
                "\n",
                "data.count()\n",
                "\n",
                "columns_finish_time = tm.time() - columns_start_time\n",
                "print_and_save_time(\"Columns conversion concluded: \" +\n",
                "                    str(columns_finish_time) + \" seconds\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### Z Score Normalization\n",
                "\n",
                "The various columns have been normalized using the z-score method, subtracting every value for the mean of its column and dividing by the column standard deviation."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "z_start_time = tm.time()\n",
                "column_list = data.columns\n",
                "column_mean_dict = dict()\n",
                "column_stddv_dict = dict()\n",
                "\n",
                "for c in column_list:\n",
                "    column_mean_dict[c] = data.agg({c: 'mean'}).head()[0]\n",
                "    column_stddv_dict[c] = data.agg({c: 'stddev'}).head()[0]\n",
                "\n",
                "data = data.select(\n",
                "  problem_to_solve,\n",
                "\n",
                "  ((data.OP_CARRIER - column_mean_dict[\"OP_CARRIER\"]) / column_stddv_dict[\"OP_CARRIER\"]).alias('OP_CARRIER'),\n",
                "\n",
                "  ((data.ORIGIN - column_mean_dict[\"ORIGIN\"]) / column_stddv_dict[\"ORIGIN\"]).alias('ORIGIN'),\n",
                "\n",
                "  ((data.DEST - column_mean_dict[\"DEST\"]) / column_stddv_dict[\"DEST\"]).alias('DEST'),\n",
                "\n",
                "  ((data.FL_DATE - column_mean_dict[\"FL_DATE\"]) / column_stddv_dict[\"FL_DATE\"]).alias('FL_DATE'),\n",
                "\n",
                "  ((data.CRS_DEP_TIME - column_mean_dict[\"CRS_DEP_TIME\"]) / column_stddv_dict[\"CRS_DEP_TIME\"]).alias('CRS_DEP_TIME'),\n",
                "\n",
                "  ((data.CRS_ARR_TIME - column_mean_dict[\"CRS_ARR_TIME\"]) /  column_stddv_dict[\"CRS_ARR_TIME\"]).alias('CRS_ARR_TIME'),\n",
                "\n",
                "  ((data.CRS_ELAPSED_TIME - column_mean_dict[\"CRS_ELAPSED_TIME\"]) / column_stddv_dict[\"CRS_ELAPSED_TIME\"]).alias('CRS_ELAPSED_TIME'),\n",
                "\n",
                "  ((data.DISTANCE - column_mean_dict[\"DISTANCE\"]) / column_stddv_dict[\"DISTANCE\"]).alias('DISTANCE'),\n",
                "\n",
                "  data.id\n",
                ")\n",
                "\n",
                "data.count()\n",
                "\n",
                "z_finish_time = tm.time() - z_start_time\n",
                "print_and_save_time(\"Z score normalization concluded: \" +\n",
                "                    str(z_finish_time) + \" seconds\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### Preprocessed dataset Saving/Loading"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def save_dataset(data):\n",
                "  data.write.format('csv').option('header', True).mode('overwrite').option(\n",
                "      'sep', ',').save('./preprocessed/' + problem_to_solve)\n",
                "  print('Preprocessed dataset saved')\n",
                "\n",
                "save_dataset(data)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def load_dataset():\n",
                "    data = spark.read.format(\"csv\") \\\n",
                "        .option(\"header\", True) \\\n",
                "        .load('./preprocessed/' + problem_to_solve)\n",
                "\n",
                "    print('Preprocessed dataset loaded')\n",
                "    return data\n",
                "\n",
                "\n",
                "if load_cached:\n",
                "    data = load_dataset().cache()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### Splitting into Folds\n",
                "\n",
                "During the main phases of preprocessing the Dataframe structure have been preferred, to use the columns name notation and the sql functions to perform transformations.\n",
                "The training part though found the RDD data structures to be more suitable for the tasks required, so a conversion has been accomplished."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "start_time = tm.time()\n",
                "folds: list[RDD] = []\n",
                "\n",
                "def format_rdd(rdd: RDD) -> RDD:\n",
                "    return rdd.map(lambda x: (float(x[0]), [float(y) for y in x[1:-1]]))\n",
                "\n",
                "temp = data\n",
                "\n",
                "k_elements_half_number = math.floor((temp.count() / fold_number) / 2)\n",
                "\n",
                "i = 0\n",
                "while i < fold_number:\n",
                "    k_positives = temp.where(\n",
                "        col(problem_to_solve) == 1).limit(k_elements_half_number)\n",
                "\n",
                "    k_negatives = temp.where(\n",
                "        col(problem_to_solve) == 0).limit(k_elements_half_number)\n",
                "\n",
                "    k_ids = k_positives.rdd.map(lambda x: x.id).collect() + \\\n",
                "        k_negatives.rdd.map(lambda x: x.id).collect()\n",
                "\n",
                "    k_sample = temp.filter(temp.id.isin(k_ids))\n",
                "    k_sample = k_sample.drop(k_sample.id)\n",
                "\n",
                "    k_sample = format_rdd(k_sample.rdd)\n",
                "\n",
                "    folds.append(k_sample)\n",
                "    temp = temp.filter(~temp.id.isin(k_ids))\n",
                "\n",
                "    print(\"Split \" + str(i + 1) + \" of \" + str(fold_number) + \" completed\")\n",
                "    print(\"Dataframe rows: \" + str(temp.count()))\n",
                "    i += 1\n",
                "\n",
                "finish_time = tm.time() - start_time\n",
                "print_and_save_time(\"Dataset splitting concluded: \" +\n",
                "                    str(finish_time) + \" seconds\")\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### Bonus: Pandas\n",
                "\n",
                "To make a comparison between PySpark parallel processing and a normal sequential data processing, dataset loading and preprocessing has been performed also with the Pandas library."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Data Load\n",
                "loading_start_time = tm.time()\n",
                "\n",
                "files = os.listdir(path)\n",
                "data = pd.DataFrame()\n",
                "\n",
                "for f in files:\n",
                "    if f.endswith('.csv'):\n",
                "        frame = pd.read_csv(filepath_or_buffer=path +\n",
                "                            '/' + f, usecols=columns_to_get)\n",
                "        frame.sample(frac=1)\n",
                "        frame = frame.head(dataset_limit)\n",
                "        data = pd.concat([data, frame])\n",
                "\n",
                "loading_finish_time = tm.time() - loading_start_time\n",
                "print_and_save_time(\"Pandas dataset acquisition concluded: \" +\n",
                "                    str(loading_finish_time) + \" seconds\")\n",
                "\n",
                "#Null values removal\n",
                "null_start_time = tm.time()\n",
                "\n",
                "data = data.dropna(how='any', axis='index')\n",
                "\n",
                "null_finish_time = tm.time() - null_start_time\n",
                "print_and_save_time(\"Pandas null values removal concluded: \" +\n",
                "                    str(null_finish_time) + \" seconds\")\n",
                "\n",
                "# Problem Selection\n",
                "selection_start_time = tm.time()\n",
                "\n",
                "irregulars = data.loc[data[problem_to_solve] == 1]\n",
                "regulars = data.loc[data[problem_to_solve] == 0]\n",
                "\n",
                "data = pd.concat([regulars.sample(len(irregulars)), irregulars]).sample(frac=1)\n",
                "\n",
                "oppositeIndex = 'DIVERTED' if problem_to_solve == 'CANCELLED' else 'CANCELLED'\n",
                "data = data.drop(oppositeIndex, axis=1)\n",
                "\n",
                "selection_finish_time = tm.time() - selection_start_time\n",
                "print_and_save_time(\"Pandas dataset balancing concluded: \" +\n",
                "                    str(selection_finish_time) + \" seconds\")\n",
                "\n",
                "conversion_start_time = tm.time()\n",
                "\n",
                "# Names Conversion\n",
                "\n",
                "def str_to_float(s: str):\n",
                "    encoding = \"utf-8\"\n",
                "    b = s.encode(encoding)\n",
                "    return float(crc32(b) & 0xffffffff) / 2**32\n",
                "\n",
                "for c in ['OP_CARRIER', 'ORIGIN', 'DEST']:\n",
                "    data[c] = data[c].apply(str_to_float)\n",
                "\n",
                "# Dates Conversion\n",
                "\n",
                "multiplier: float = 1 / 365\n",
                "\n",
                "def date_to_day_of_year(date_string) -> float:\n",
                "    date = dt.strptime(date_string, \"%Y-%m-%d\")\n",
                "    day = date.timetuple().tm_yday - 1\n",
                "    return day * multiplier\n",
                "\n",
                "data[\"FL_DATE\"] = data[\"FL_DATE\"].apply(date_to_day_of_year)\n",
                "\n",
                "# Time Conversion\n",
                "    \n",
                "def time_to_interval(time) -> float:\n",
                "    t = int(float(time))\n",
                "    h = t // 100\n",
                "    m = t % 100\n",
                "    t = h * 60 + m\n",
                "    return float(t / 1140)\n",
                "\n",
                "for c in [\"CRS_DEP_TIME\", \"CRS_ARR_TIME\", \"CRS_ELAPSED_TIME\"]:\n",
                "    data[c] = data[c].apply(time_to_interval)\n",
                "\n",
                "# Distance Conversion\n",
                "    \n",
                "multiplier: float = float(1) / float(max_distance)\n",
                "\n",
                "data[\"DISTANCE\"] = data[\"DISTANCE\"].apply(lambda x: x * multiplier)\n",
                "\n",
                "conversion_finish_time = tm.time() - conversion_start_time\n",
                "print_and_save_time(\"Pandas dataset conversions concluded: \" +\n",
                "                    str(conversion_finish_time) + \" seconds\")\n",
                "\n",
                "normalization_start_time = tm.time()\n",
                "\n",
                "#Z-score normalization\n",
                "\n",
                "def z_score_normalize(x, m, s) -> float:\n",
                "    return (x - m) / s\n",
                "\n",
                "column_list = list(data)\n",
                "column_list.remove(problem_to_solve)\n",
                "\n",
                "for c in column_list:\n",
                "    column_mean = data[c].mean()\n",
                "    column_stddv = data[c].std()\n",
                "    data[c] = data[c].apply(z_score_normalize, args=(column_mean, column_stddv))\n",
                "\n",
                "normalization_finish_time = tm.time() - normalization_start_time\n",
                "print_and_save_time(\"Pandas dataset normalization concluded: \" +\n",
                "                    str(normalization_finish_time) + \" seconds\")\n",
                "\n",
                "fold_start_time = tm.time()\n",
                "# Create Folds\n",
                "\n",
                "folds = []\n",
                "\n",
                "data = data.drop_duplicates()\n",
                "\n",
                "irregulars = data.loc[data[problem_to_solve] == 1]\n",
                "regulars = data.loc[data[problem_to_solve] == 0]\n",
                "\n",
                "k_elements_half_number = round((len(data) / fold_number) / 2)\n",
                "\n",
                "for i in range(1, fold_number + 1):\n",
                "    k_irregulars_sample = irregulars.head(k_elements_half_number)\n",
                "    k_regulars_sample = regulars.head(k_elements_half_number)\n",
                "    k_sample = pd.concat([k_irregulars_sample, k_regulars_sample])\n",
                "\n",
                "    folds.append(k_sample)\n",
                "    irregulars = irregulars.drop(k_irregulars_sample.index)\n",
                "    regulars = regulars.drop(k_regulars_sample.index)\n",
                "\n",
                "fold_finish_time = tm.time() - fold_start_time\n",
                "print_and_save_time(\"Pandas dataset folding concluded: \" +\n",
                "                    str(fold_finish_time) + \" seconds\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Models"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Generic Functions"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def sigmoid(x):\n",
                "    '''\n",
                "    Calculates the sigmoid of the given data\n",
                "    '''\n",
                "    g = 1.0 / (1.0 + np.exp(-x))\n",
                "    return g\n",
                "\n",
                "def binary_cross_entropy(y, y_label, w, l2):\n",
                "    '''\n",
                "    Calculates the binary cross entropy loss of the calculated y and the given y_label\n",
                "    '''\n",
                "    loss = -np.mean(y_label*(np.log(y)) + (1-y_label)\n",
                "                    * np.log(1-y)) + regularize(w, l2)\n",
                "    return loss\n",
                "\n",
                "def regularize(W, l2):\n",
                "    '''\n",
                "    Calculates the regularization term for the loss\n",
                "    '''\n",
                "    return (l2 / 2) * np.sum(np.square(W))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Parallel Model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "@dataclass\n",
                "class ParallelLogisticRegression:\n",
                "    iterations: int\n",
                "    learning_rate: float\n",
                "    batch_size: int\n",
                "    l2: float\n",
                "    W: Broadcast\n",
                "    b: float\n",
                "\n",
                "def parallel_initialize(self: ParallelLogisticRegression, feature_number: int):\n",
                "    self.W = context.broadcast(np.random.rand(feature_number))\n",
                "    self.b = np.random.rand()\n",
                "\n",
                "def parallel_train(self: ParallelLogisticRegression, data: RDD):\n",
                "\n",
                "    if self.batch_size != 0:\n",
                "        num_chunks = data.count() // self.batch_size\n",
                "        chunk_percent = 1/num_chunks\n",
                "        batches = data.randomSplit([chunk_percent] * num_chunks)\n",
                "    else:\n",
                "        batches = [data]\n",
                "\n",
                "    losses = []\n",
                "    gradients = []\n",
                "\n",
                "    for _ in range(self.iterations):\n",
                "        _losses = []\n",
                "        _gradients = []\n",
                "\n",
                "        for batch in batches:\n",
                "            batch = batch.cache()\n",
                "            Y = parallel_evaluate(self, batch)\n",
                "            _losses.append(parallel_binary_cross_entropy(self, batch.map(lambda x: x[0]).zip(Y)))\n",
                "            (dW, db) = parallel_gradient(self, batch, Y)\n",
                "            _gradients.append(dW)\n",
                "            parallel_update(self, dW, db)\n",
                "        losses.append(np.mean(_losses))\n",
                "        gradients.append(np.mean(_gradients))\n",
                "\n",
                "    return (losses, gradients)\n",
                "\n",
                "\n",
                "def parallel_evaluate(self: ParallelLogisticRegression, X: RDD) -> RDD:\n",
                "    Z: RDD = X.map(lambda x: np.dot(x[1], self.W.value))\n",
                "    Z = Z.map(lambda x: sigmoid(x))\n",
                "    return Z\n",
                "\n",
                "def parallel_binary_cross_entropy(self: ParallelLogisticRegression, X_Y: RDD)-> float:\n",
                "    L: RDD = X_Y.map(lambda y: y[0] * np.log(y[1]) + (1 - y[0]) * np.log(1 -  y[1]))\n",
                "    return -L.reduce(lambda a, b: a + b)/L.count() + regularize(self.W.value, self.l2)\n",
                "\n",
                "def parallel_gradient(self: ParallelLogisticRegression, X: RDD, Y: RDD)-> tuple[np.ndarray, np.ndarray]:\n",
                "    m = X.count()\n",
                "    dw = X.zip(Y).map(lambda x: np.dot((x[1] - x[0][0]), x[0][1])).reduce(lambda a, b: (a + b) * 1/m + self.W.value * self.l2)\n",
                "    db = X.zip(Y).map(lambda x: x[1] - x[0][0]).reduce(lambda a, b: a + b) * 1/m\n",
                "    return dw, db\n",
                "\n",
                "def parallel_update(self: ParallelLogisticRegression, dW: list[float], db: float):\n",
                "    self.W = context.broadcast(self.W.value - self.learning_rate * dW)\n",
                "    self.b = self.b - self.learning_rate * db"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Serial Model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "class SerialLogisticRegression():\n",
                "    def __init__(self, iterations: int, learning_rate: float, batch_size: int, l2: float):\n",
                "        self.iterations = iterations\n",
                "        self.learning_rate = learning_rate\n",
                "        self.batch_size = batch_size\n",
                "        self.l2 = l2\n",
                "\n",
                "    def initialize(self, columns_number):\n",
                "        self.W = np.random.rand(columns_number)\n",
                "        self.b = np.random.rand()\n",
                "\n",
                "    def evaluate(self, X):\n",
                "        Z = np.dot(X, self.W) + self.b\n",
                "        Z = sigmoid(Z)\n",
                "        return Z\n",
                "\n",
                "    def gradient(self, X, Y, Y_label):\n",
                "        '''\n",
                "        Calculates the gradient w.r.t weights and bias\n",
                "        '''\n",
                "\n",
                "        # Number of training examples.\n",
                "        m = X.shape[0]\n",
                "\n",
                "        # Gradient of loss w.r.t weights with regularization\n",
                "        dw = (1/m)*np.dot(X.T, (Y - Y_label)) + self.l2 * self.W\n",
                "\n",
                "        # Gradient of loss w.r.t bias with regularization\n",
                "        db = (1/m)*np.sum((Y - Y_label))\n",
                "\n",
                "        return dw, db\n",
                "\n",
                "    def update(self, dW, db):\n",
                "        self.W = self.W - self.learning_rate * dW\n",
                "        self.b = self.b - self.learning_rate * db\n",
                "\n",
                "    def train(self, X, Y_labels):\n",
                "        losses = []\n",
                "        gradients = []\n",
                "\n",
                "        if self.batch_size == 0:\n",
                "            self.batch_size = X.shape[0]\n",
                "\n",
                "        for _ in range(self.iterations):\n",
                "            _losses = []\n",
                "            _gradients = []\n",
                "            for b in range(X.shape[0]//self.batch_size):\n",
                "                b_X = X[b*self.batch_size:b*self.batch_size+self.batch_size, :]\n",
                "                b_Y_labels = Y_labels[b*self.batch_size:b *\n",
                "                                      self.batch_size+self.batch_size]\n",
                "                Y = self.evaluate(b_X)\n",
                "                _losses.append(binary_cross_entropy(\n",
                "                    Y, b_Y_labels, self.W, self.l2))\n",
                "                (dW, db) = self.gradient(b_X, Y, b_Y_labels)\n",
                "                _gradients.append(dW)\n",
                "                self.update(dW, db)\n",
                "            losses.append(np.mean(_losses))\n",
                "            gradients.append(np.mean(_gradients))\n",
                "\n",
                "        return (losses, gradients)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Experiments\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from sklearn import metrics\n",
                "\n",
                "def describe(labels: RDD, predictions: RDD):\n",
                "    zipped = labels.zip(predictions)\n",
                "    tn = zipped.filter(lambda x: round(x[0]) == 0 and round(x[1]) == 0).count()\n",
                "    tp = zipped.filter(lambda x: round(x[0]) == 1 and round(x[1]) == 1).count()\n",
                "    fn = zipped.filter(lambda x: round(x[0]) == 1 and round(x[1]) == 0).count()\n",
                "    fp = zipped.filter(lambda x: round(x[0]) == 0 and round(x[1]) == 1).count()\n",
                "    precision = tp / (tp + fp)\n",
                "    recall = tp / (tp + fn)\n",
                "    f1 = 2 * (precision * recall) / (precision + recall)\n",
                "    acc = (tp + tn)/(tp + tn + fn + fp)\n",
                "    specificity = tn/(tn+fp)\n",
                "    auroc = metrics.roc_auc_score(labels.map(lambda x: round(x)).collect(), predictions.map(lambda x: round(x)).collect())\n",
                "    return pd.DataFrame([[tn, tp, fn, fp, precision, recall, f1, acc, specificity, auroc]], columns=['TN', 'TP', 'FN', 'FP', 'Precision', 'Recall', 'F1', 'Accuracy', 'Specificity', \"AUROC\"])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def make_roc(labels: RDD, results: RDD):\n",
                "    labels = labels.collect()\n",
                "    results = results.collect()\n",
                "    labels_and_results = sorted(list(zip(labels, results)), key=lambda x: x[1])\n",
                "\n",
                "    labels_by_weights = np.array([k for (k, _) in labels_and_results])\n",
                "\n",
                "    length = labels_by_weights.size\n",
                "\n",
                "    true_positives = labels_by_weights.cumsum()\n",
                "\n",
                "    num_positive = true_positives[-1]\n",
                "\n",
                "    false_positives = np.arange(1.0, length + 1, 1.) - true_positives\n",
                "\n",
                "    true_positives_rate = true_positives / num_positive\n",
                "    false_positives_rate = false_positives / (length - num_positive)\n",
                "\n",
                "    fig, ax = plt.subplots()\n",
                "    ax.set_xlim(-.05, 1.05), ax.set_ylim(-.05, 1.05)\n",
                "    ax.set_ylabel('True Positive Rate (Sensitivity)')\n",
                "    ax.set_xlabel('False Positive Rate (1 - Specificity)')\n",
                "    plt.plot(false_positives_rate, true_positives_rate,\n",
                "             color='#8cbfd0', linestyle='-', linewidth=3.)\n",
                "    plt.plot((0., 1.), (0., 1.), linestyle='--',\n",
                "             color='#d6ebf2', linewidth=2.)\n",
                "    plt.show()\n",
                "\n",
                "def plot_loss_gradient(iterations, train_losses, gradients):\n",
                "    fig, ax = plt.subplots()\n",
                "    ax.set_xlabel('Iterations')\n",
                "    ax.set_ylabel('Loss/Gradient')\n",
                "    ax.plot(range(iterations), train_losses, label='Loss')\n",
                "    ax.plot(range(iterations), gradients, label='Gradient')\n",
                "    ax.grid()\n",
                "    ax.legend()\n",
                "\n",
                "    fig.clear()\n",
                "    plt.close()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import plotly.graph_objects as go\n",
                "\n",
                "def make_3d(results: list):\n",
                "    chart_data = [np.array([r[0].iterations, r[0].lr, r[0].l2, r[3]]) for r in results]\n",
                "    chart_data = pd.DataFrame(chart_data, columns= ['iterations', 'lr', 'l2', 'loss'])\n",
                "\n",
                "    fig = go.Figure(data=[go.Scatter3d(\n",
                "        x=chart_data['lr'],\n",
                "        y=chart_data['l2'],\n",
                "        z=chart_data['iterations'],\n",
                "        mode='markers',\n",
                "        text=('lr', 'l2', 'iterations'),\n",
                "        marker=dict(\n",
                "            color=chart_data['loss'], \n",
                "            colorscale='Viridis',\n",
                "            colorbar=dict(thickness=20)\n",
                "        )\n",
                "    )])\n",
                "\n",
                "    fig.update_layout(\n",
                "        autosize=False,\n",
                "        width=600, \n",
                "        height=600,\n",
                "        title='', \n",
                "        margin=dict(l=0, r=0, b=0, t=0),\n",
                "        scene=dict(\n",
                "            xaxis_title='LR',\n",
                "            yaxis_title='L2',\n",
                "            zaxis_title='Iterations',\n",
                "        ),\n",
                "    )\n",
                "\n",
                "    fig.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Hyperparameters Tuning\n",
                "Here a class to tune the hyperparameters is defined. It iterates a grid of parameters and trains a model for each configuration"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import itertools\n",
                "\n",
                "grid: dict[str, list] = { 'iter': [10, 20, 50], 'lr': [0.001, 0.01, 0.1], 'l2': [1, 0.1, 0.01]}\n",
                "\n",
                "class Tuner:\n",
                "    def __init__(self, grid: dict, model_factory) -> None:\n",
                "        self.params = list(itertools.product(*grid.values()))\n",
                "        self.model_factory = model_factory\n",
                "\n",
                "    def search(self, input: list[RDD]):\n",
                "        results = list()\n",
                "        for i in self.params:\n",
                "            model = self.model_factory(*i)\n",
                "            time, predictions, test_loss, train_losses = model.train(input)\n",
                "            print(\"Completed configuration \" + '|'.join(map(lambda x: str(x), i)))\n",
                "            results.append((model, time, predictions, test_loss, train_losses))\n",
                "        return results\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### K-Fold Cross Validation\n",
                "The following code defines a base class with train and evaluation methods to apply the K-Fold Cross Validation to each model. "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "class KFoldTrainer:\n",
                "    def __init__(self, iterations, lr, l2, batch_size):\n",
                "        self.iterations = iterations\n",
                "        self.lr = lr\n",
                "        self.l2 = l2\n",
                "        self.batch_size = batch_size\n",
                "\n",
                "    def train(self, data: list[RDD]):\n",
                "        test_set = data[0]\n",
                "        rest = data[1:]\n",
                "        train_losses = []\n",
                "        times = []\n",
                "        for i, fold in enumerate(rest):\n",
                "            evaluation_set = fold\n",
                "            remaining_folds= rest[:i] + rest[i + 1:]\n",
                "            train_set = remaining_folds[0]\n",
                "            for train_fold in remaining_folds[1:]:\n",
                "                train_set = train_set.union(train_fold)\n",
                "            t = tm.time()\n",
                "            self.train_impl(train_fold)\n",
                "            times.append(tm.time() - t)\n",
                "            _, loss = self.test_impl(evaluation_set)\n",
                "            train_losses.append(loss)\n",
                "        predictions, test_loss = self.test_impl(test_set)\n",
                "        return sum(times), predictions, test_loss, train_losses"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Parallel Implementation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "class ParallelModelEvaluator(KFoldTrainer):\n",
                "    def __init__(self, iterations, lr, l2, batch_size):\n",
                "        super().__init__(iterations, lr, l2, batch_size)\n",
                "        self.model = ParallelLogisticRegression(self.iterations, self.lr, self.batch_size, self.l2, None, None)\n",
                "        parallel_initialize(self.model, 7)\n",
                "\n",
                "    def train_impl(self, train_data: RDD):\n",
                "        return parallel_train(self.model, train_data)\n",
                "    \n",
                "    def test_impl(self, test_data: RDD):\n",
                "        value: RDD = parallel_evaluate(self.model, test_data)\n",
                "        return value, parallel_binary_cross_entropy(self.model, test_data.map(lambda x: x[0]).zip(value))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "t = Tuner(grid, lambda it, lr, l2: ParallelModelEvaluator(it, lr, l2, 0))\n",
                "par_results = t.search(folds)\n",
                " \n",
                "par_best = min(par_results, key=lambda x: x[3])\n",
                "par_best_model = par_best[0]\n",
                "par_best_loss = par_best[3]\n",
                "\n",
                "print(\"Iterations {} Lr {} L2 {} Loss {}\".format(par_best_model.iterations, par_best_model.lr, par_best_model.l2, par_best_loss))\n",
                "print(\"Total time: {}\".format(sum([r[1] for r in par_results])))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "The following is a representation of the loss for each possible configuration. The loss is represented with a color"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "predictions = par_best[2]\n",
                "labels = folds[0].map(lambda x: x[0]).coalesce(1)\n",
                "predictions = predictions.coalesce(1)\n",
                "describe(labels, predictions)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "make_3d(par_results)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Sequential Implementation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "class SequentialEvaluator(KFoldTrainer):\n",
                "    def __init__(self, iterations, lr, l2, batch_size):\n",
                "        super().__init__(iterations, lr, l2, batch_size)\n",
                "        self.model = SerialLogisticRegression(self.iterations, self.lr, self.batch_size, self.l2)\n",
                "        self.model.initialize(7)\n",
                "\n",
                "    def train_impl(self, train_data: RDD):\n",
                "        return self.model.train(np.array(train_data.map(lambda x: x[1]).collect()), np.array(train_data.map(lambda x: x[0]).collect()))\n",
                "\n",
                "    def test_impl(self, test_data: RDD):\n",
                "        res = self.model.evaluate(np.array(test_data.map(lambda x: x[1]).collect()))\n",
                "        return res, binary_cross_entropy(res, np.array(test_data.map(lambda x: x[0]).collect()), self.model.W, self.l2)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "t = Tuner(grid, lambda it, lr, l2: SequentialEvaluator(it, lr, l2, 0))\n",
                "\n",
                "seq_results = t.search(folds)\n",
                " \n",
                "seq_best = min(seq_results, key=lambda x: x[3])\n",
                "seq_best_model = seq_best[0]\n",
                "seq_best_loss = seq_best[3]\n",
                "\n",
                "print(\"Best Model: Iterations {} Lr {} L2 {} Loss {} in {}s\".format(seq_best_model.iterations, seq_best_model.lr, seq_best_model.l2, seq_best_loss, seq_best[1]))\n",
                "print(\"Total time: {}\".format(sum([r[1] for r in seq_results])))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "predictions = seq_best[2]\n",
                "labels = folds[0].map(lambda x: x[0]).coalesce(1)\n",
                "predictions = context.parallelize(predictions).coalesce(1)\n",
                "describe(labels, predictions)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "make_roc(labels, predictions)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "make_3d(seq_results)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Mini Batch\n",
                "The following experiment consists in using the mini batch feature using the best hyperparameters to find differences"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "mini_batch_eval = SequentialEvaluator(20, 0.1, 0.01, 500)\n",
                "time, mb_predictions, mb_test_loss, mb_train_losses = mini_batch_eval.train(folds)\n",
                "print(\"Mini Batch Impl: {} in {}s\".format(mb_test_loss, time))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "labels = folds[0].map(lambda x: x[0]).coalesce(1)\n",
                "predictions = context.parallelize(mb_predictions).coalesce(1)\n",
                "describe(labels, predictions)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Pyspark ML Implementations\n",
                "The following cells use some state-of-the-art models provided by the Pyspark ML library, in particular their implementation of the Logistic Regression and Decision Tree models.\n",
                "\n",
                "They should be most performant implementations of a distributed machine learning model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from pyspark.ml.feature import VectorAssembler\n",
                "\n",
                "ml_data = data.select([col(c).cast('float').alias(c) if c != problem_to_solve else col(c).cast('float').alias('label') for c in data.columns[:-1]])\n",
                "\n",
                "assembler = VectorAssembler(inputCols=ml_data.columns[1:-1], outputCol='features')\n",
                "\n",
                "ml_data = assembler.transform(ml_data).select(['features', 'label'])\n",
                "\n",
                "train_set, test_set = ml_data.randomSplit([0.9, 0.1])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
                "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
                "\n",
                "class SparkMLTuner:\n",
                "    def __init__(self, estimator, grid_builder: ParamGridBuilder, num_fold: int):\n",
                "        self.evaluator = BinaryClassificationEvaluator()\n",
                "        self.cv = CrossValidator(estimator=estimator, estimatorParamMaps=grid_builder.build(), evaluator=self.evaluator, numFolds=num_fold)\n",
                "\n",
                "    def train(self, data: ps.DataFrame):\n",
                "        self.model = self.cv.fit(data)\n",
                "        return self.model.bestModel.params\n",
                "\n",
                "    def test(self, data: ps.DataFrame):\n",
                "        predictions = self.model.transform(data)\n",
                "        return predictions, self.evaluator.evaluate(predictions)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Logistic Regression"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from pyspark.ml.classification import LogisticRegression\n",
                "\n",
                "e = LogisticRegression(featuresCol='features', labelCol='label')\n",
                "g = ParamGridBuilder().addGrid(e.regParam, grid['l2']).addGrid(e.maxIter, grid['iter'])\n",
                "t1 = SparkMLTuner(e, g, 10)\n",
                "t1.train(train_set)\n",
                "predictions, loss = t1.test(test_set)\n",
                "\n",
                "labels = test_set.select(col('label')).rdd.map(lambda x: float(x[0]))\n",
                "predictions = predictions.select(col('prediction')).rdd.map(lambda x: float(x[0]))\n",
                "\n",
                "print(\"Loss \" + str(loss))\n",
                "\n",
                "describe(labels, predictions)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "make_roc(labels, predictions)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Next the weights from the Pyspark ML model and the naive implementation are compared to see their difference"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "pyspark_ml_weights = t1.model.bestModel.coefficients\n",
                "\n",
                "par_impl_weights = seq_best[0].model.W \n",
                "\n",
                "print(par_impl_weights)\n",
                "print(pyspark_ml_weights)\n",
                "\n",
                "np.allclose(pyspark_ml_weights, par_impl_weights, rtol=0.1, atol=0.1)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Decision Tree"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from pyspark.ml.classification import DecisionTreeClassifier\n",
                "e = DecisionTreeClassifier(featuresCol='features', labelCol='label')\n",
                "g = ParamGridBuilder()\n",
                "t = SparkMLTuner(e, g, 10)\n",
                "t.train(train_set)\n",
                "predictions, loss = t.test(test_set)\n",
                "\n",
                "labels = test_set.select(col('label')).rdd.map(lambda x: float(x[0]))\n",
                "predictions = predictions.select(col('prediction')).rdd.map(lambda x: float(x[0]))\n",
                "\n",
                "print(\"Loss \" + str(loss))\n",
                "\n",
                "describe(labels, predictions)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "make_roc(labels, predictions)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.5 (tags/v3.10.5:f377153, Jun  6 2022, 16:14:13) [MSC v.1929 64 bit (AMD64)]"
        },
        "orig_nbformat": 4,
        "vscode": {
            "interpreter": {
                "hash": "e51fdbc37c5adaa12a9ed97b50fdaf0ff46be7ee1a114cc405b6eaf0c36d1bf8"
            }
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
